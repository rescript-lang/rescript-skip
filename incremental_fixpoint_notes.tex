\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{amsmath,amssymb}
\usepackage{amsthm}

\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{remark}{Remark}

\title{Incremental Fixpoint Computation:\\A Two-Level Architecture}
\author{}
\date{}

\begin{document}
\maketitle

\begin{abstract}
We observe that the incremental dead code elimination (DCE) algorithm from our reactive DCE work is an instance of a more general pattern: \emph{incremental fixpoint computation}.
This note proposes a two-level architecture for incremental fixpoints:
(1)~a low-level API that assumes user-provided incremental operations, and
(2)~a potential high-level DSL where these operations are derived automatically from a structured definition of the fixpoint operator.
The relationship between these levels is analogous to that between manual gradient computation and automatic differentiation.
\end{abstract}

\section{Motivation: DCE as Incremental Fixpoint}

In reactive DCE, the live set is defined as the least fixpoint of a monotone operator:
\[
F_G(S) = G.\mathsf{roots} \cup \{ v \mid \exists u \in S.\, (u,v) \in G.\mathsf{edges} \}
\]
That is, $\mathsf{liveSet}(G) = \mathsf{lfp}(F_G)$.

When the graph changes ($G \to G' = G \pm f$), we want to update the fixpoint incrementally rather than recomputing from scratch.
The key observations are:
\begin{itemize}
  \item \textbf{Expansion} ($G \to G \oplus f$): The operator grows, so $\mathsf{lfp}(F_G) \subseteq \mathsf{lfp}(F_{G'})$. The old fixpoint is an underapproximation; we iterate upward.
  \item \textbf{Contraction} ($G \to G \ominus f$): The operator shrinks, so $\mathsf{lfp}(F_{G'}) \subseteq \mathsf{lfp}(F_G)$. The old fixpoint is an overapproximation; we must remove unjustified elements.
\end{itemize}

This pattern---incremental maintenance of a least fixpoint under changes to the underlying operator---arises in many domains beyond DCE.

\section{The General Pattern}

\begin{definition}[Monotone Fixpoint Problem]
Given a complete lattice $(L, \sqsubseteq)$ and a monotone operator $F : L \to L$, the \emph{least fixpoint} is $\mathsf{lfp}(F) = \bigcap \{ x \mid F(x) \sqsubseteq x \}$.
\end{definition}

For set-based fixpoints (our focus), $L = \mathcal{P}(A)$ for some element type $A$, ordered by $\subseteq$, and $F$ is typically of the form:
\[
F(S) = \mathsf{base} \cup \mathsf{step}(S)
\]
where $\mathsf{base}$ provides seed elements and $\mathsf{step}$ derives new elements from existing ones.

\begin{definition}[Incremental Fixpoint Problem]
Given:
\begin{itemize}
  \item A current fixpoint $S = \mathsf{lfp}(F)$
  \item A change that transforms $F$ into $F'$
\end{itemize}
Compute $S' = \mathsf{lfp}(F')$ efficiently, in time proportional to $|S' \triangle S|$ rather than $|S'|$.
\end{definition}

\section{Level 1: Low-Level Incremental Fixpoint API}

The low-level API assumes the user provides the necessary incremental operations.

\subsection{Required Ingredients}

\paragraph{For Semi-Naive Expansion.}
When $F' \supseteq F$ (the operator grows), we use \emph{semi-naive evaluation}:
\begin{itemize}
  \item Maintain the ``delta'' $\Delta S$ = elements added in the last iteration
  \item Instead of computing $F'(S)$, compute only $\mathsf{stepFromDelta}(\Delta S) \setminus S$
\end{itemize}

The user provides:
\[
\mathsf{stepFromDelta} : \mathsf{Params} \times \mathcal{P}(A) \to \mathcal{P}(A)
\]
Given the current parameters and a delta set, return elements derivable from that delta.

\begin{example}[DCE]
$\mathsf{stepFromDelta}(G, \Delta) = \{ v \mid \exists u \in \Delta.\, (u,v) \in G.\mathsf{edges} \}$
\end{example}

\paragraph{For Counting-Based Contraction.}
When $F' \subseteq F$ (the operator shrinks), we use \emph{well-founded cascade}:
\begin{itemize}
  \item Use the iterative construction rank to identify well-founded derivers
  \item Remove elements with no well-founded derivers (and not in base)
  \item Propagate: removing an element may eliminate derivers for others
\end{itemize}

The key insight: cycle members have equal rank, so they don't provide well-founded support to each other. This correctly handles unreachable cycles.

\subsection{Specification (Not Implementation)}

\textbf{Important:} What follows is a \emph{mathematical specification} of what the update algorithms compute, not an executable implementation. The Lean formalization proves correctness of these specifications but does not provide runnable code.

The user provides:
\begin{itemize}
  \item $\mathsf{base}$: seed elements
  \item $\mathsf{stepFromDelta}$: derive new elements from a delta
  \item Proof that step is \emph{element-wise}: $x \in \mathsf{step}(S) \Rightarrow \exists y \in S.\, x \in \mathsf{step}(\{y\})$
  \item Proof that step is \emph{additive}: $\mathsf{step}(A \cup B) = \mathsf{step}(A) \cup \mathsf{step}(B)$
\end{itemize}

\begin{example}[DCE]
DCE satisfies both properties: if $v$ is reachable from $S$, there's a specific predecessor $u \in S$ with $(u,v) \in \mathsf{edges}$.
\end{example}

\subsection{Update Algorithms (Specification)}

\paragraph{Expansion.}
When $F$ grows, semi-naive iteration computes:
\begin{align*}
C_0 &= \mathsf{lfp}(F) & \Delta_0 &= \mathsf{lfp}(F) \\
C_{n+1} &= C_n \cup \Delta_{n+1} & \Delta_{n+1} &= \mathsf{step}'(\Delta_n) \setminus C_n
\end{align*}
The sequence $C_n$ is monotonically increasing. If it stabilizes (i.e., $\Delta_{n+1} = \emptyset$ for some $n$), then $C_n = \mathsf{lfp}(F')$.

\paragraph{Contraction.}
When $F$ shrinks, well-founded cascade computes:
\[
K_0 = \mathsf{lfp}(F), \qquad K_{n+1} = K_n \setminus \{ x \in K_n \mid x \notin \mathsf{base}' \land \text{no wf-deriver in } K_n \}
\]
where an element's \emph{rank} is when it first appears in $F^n(\emptyset)$, and $y$ is a \emph{well-founded deriver} of $x$ if $\mathsf{rank}(y) < \mathsf{rank}(x)$ and $x \in \mathsf{step}'(\{y\})$.
Cycles don't provide support because cycle members have equal rank.

The sequence $K_n$ is monotonically decreasing. If it stabilizes, then $K_n = \mathsf{lfp}(F')$.

\subsection{From Specification to Implementation}

The specifications above operate on abstract sets and assume convergence. A real implementation requires additional ingredients:

\paragraph{1. Finite representation.}
The specifications use $\mathsf{Set}\ A$ (arbitrary sets). An implementation needs:
\begin{itemize}
  \item Finite domain or lazy enumeration
  \item Efficient set operations (membership, union, difference)
\end{itemize}

\paragraph{2. Termination.}
The specifications define $K^* = \bigcap_n K_n$ (infinite intersection). An implementation needs:
\begin{itemize}
  \item Proof that iteration stabilizes in finite steps
  \item Or: a bound on the number of iterations (e.g., $|A|$ for finite domains)
\end{itemize}

\paragraph{3. Rank computation.}
Well-founded cascade requires comparing ranks. An implementation needs:
\begin{itemize}
  \item Either: precompute and store ranks for all elements
  \item Or: compute ranks on-demand during cascade
  \item For DCE: rank = BFS distance from roots (computable)
\end{itemize}

\paragraph{4. Detecting stabilization.}
\begin{itemize}
  \item Expansion: check if $\Delta_{n+1} = \emptyset$
  \item Contraction: check if $K_{n+1} = K_n$ (no elements removed)
\end{itemize}

\paragraph{5. Complexity analysis.}
\begin{itemize}
  \item Expansion: $O(\text{new elements})$ iterations, each processing a delta
  \item Contraction: $O(|K_0|)$ iterations in the worst case
\end{itemize}

\begin{remark}[What the Lean Formalization Provides]
The Lean formalization proves:
\begin{itemize}
  \item \textbf{Correctness:} If the algorithms stabilize, they compute the new fixpoint
  \item \textbf{Soundness:} Intermediate results are always subsets/supersets of the target
\end{itemize}
It does \emph{not} provide:
\begin{itemize}
  \item Termination proofs
  \item Complexity bounds  
  \item Executable code
\end{itemize}
\end{remark}

\subsection{Formal Definitions and Correctness}

\newtheorem{theorem}{Theorem}

\subsubsection{Decomposed Operators}

\begin{definition}[Decomposed Operator]
An operator $F : \mathcal{P}(A) \to \mathcal{P}(A)$ is \emph{decomposed} if $F(S) = B \cup \mathsf{step}(S)$ where $B$ is a fixed base set and $\mathsf{step}$ is monotone: $S \subseteq T \Rightarrow \mathsf{step}(S) \subseteq \mathsf{step}(T)$.
\end{definition}

\begin{definition}[Operator Expansion and Contraction]
We say $F$ \emph{expands to} $F'$, written $F \sqsubseteq F'$, if $\forall S.\, F(S) \subseteq F'(S)$.
Dually, $F$ \emph{contracts to} $F'$ if $F' \sqsubseteq F$.
\end{definition}

\begin{theorem}[Fixpoint Monotonicity]
\leavevmode
\begin{enumerate}
\item If $F \sqsubseteq F'$ then $\mathsf{lfp}(F) \subseteq \mathsf{lfp}(F')$.
\item If $F' \sqsubseteq F$ then $\mathsf{lfp}(F') \subseteq \mathsf{lfp}(F)$.
\end{enumerate}
\end{theorem}

\subsubsection{Semi-Naive Iteration (Expansion)}

\begin{definition}[Semi-Naive Iteration]
Given a decomposed operator $(B, \mathsf{step})$ and initial set $I$, define:
\begin{align*}
C_0 &= I & \Delta_0 &= I \\
C_{n+1} &= C_n \cup \Delta_{n+1} & \Delta_{n+1} &= \mathsf{step}(\Delta_n) \setminus C_n
\end{align*}
\end{definition}

\begin{theorem}[Semi-Naive Monotonicity]
$C_n \subseteq C_{n+1}$ for all $n \geq 0$.
\end{theorem}

\begin{theorem}[Semi-Naive Soundness]
If $I \subseteq \mathsf{lfp}(F)$, then $C_n \subseteq \mathsf{lfp}(F)$ for all $n \geq 0$.
\end{theorem}

\subsubsection{Well-Founded Cascade (Contraction)}
\label{sec:wf-derivations}

\begin{definition}[Iterative Construction and Rank]
The least fixpoint is constructed iteratively:
\begin{align*}
F^0(\emptyset) &= \emptyset, \qquad
F^{n+1}(\emptyset) = F(F^n(\emptyset)), \qquad
\mathsf{lfp}(F) = \bigcup_{n \geq 0} F^n(\emptyset)
\end{align*}
The \emph{rank} of $x \in \mathsf{lfp}(F)$ is the minimum $n$ such that $x \in F^n(\emptyset)$.
Elements not in $\mathsf{lfp}(F)$ have no finite rank.
\end{definition}

\begin{definition}[Well-Founded Derivation]
Element $y$ \emph{well-foundedly derives} $x$ if $\mathsf{rank}(y) < \mathsf{rank}(x)$ and $x \in \mathsf{step}(\{y\})$.
\end{definition}

\begin{definition}[Well-Founded Cascade]
Given initial set $I$:
\begin{align*}
\mathsf{wfShouldDie}(S) &= \{ x \in S \mid x \notin B \land \text{no wf-deriver in } S \} \\
K_0 &= I, \qquad K_{n+1} = K_n \setminus \mathsf{wfShouldDie}(K_n)
\end{align*}
Key insight: cycle members have equal (or no) rank, so they don't provide well-founded support to each other.
\end{definition}

\begin{theorem}[Cascade Monotonicity]
$K_{n+1} \subseteq K_n$ for all $n \geq 0$.
\end{theorem}

\begin{theorem}[Base Preservation]
If $B \subseteq I$, then $B \subseteq K_n$ for all $n \geq 0$.
\end{theorem}

\subsubsection{Overall Correctness}

\begin{theorem}[Expansion Correctness]
Let $F \sqsubseteq F'$ (expansion), $S = \mathsf{lfp}(F)$, and $S' = \mathsf{lfp}(F')$.
If semi-naive iteration from $S$ with operator $F'$ stabilizes, then $C_n = S'$.
\end{theorem}

\begin{theorem}[Contraction Correctness]
Let $F' \sqsubseteq F$ (contraction), $S = \mathsf{lfp}(F)$, $S' = \mathsf{lfp}(F')$.
Assume $\mathsf{step}$ is \emph{element-wise}: $x \in \mathsf{step}(T) \Rightarrow \exists y \in T.\, x \in \mathsf{step}(\{y\})$.
Then well-founded cascade from $S$ converges to $K^* = S'$.
\end{theorem}

\begin{remark}[Lean Formalization]
All definitions and theorems are formalized in Lean.%
\footnote{See \texttt{lean-formalisation/IncrementalFixpoint.lean}.}

\textbf{Fully proven:}
Well-founded contraction correctness, semi-naive soundness, fixpoint monotonicity, all helper lemmas.

\textbf{Remaining assumption} (1 \texttt{sorry}):
Expansion completeness requires proving $\mathsf{step}(\mathsf{current}) \subseteq \mathsf{current}$ when stable.

The API requires: \texttt{stepElementWise} and \texttt{stepAdditive}. Both hold for DCE.
\end{remark}

\section{Level 2: DSL with Automatic Derivation (Future)}

The low-level API requires the user to provide $\mathsf{stepFromDelta}$ and prove that step is element-wise and additive.
A higher-level approach would let users define $F$ in a structured DSL, from which these properties are derived automatically.

\subsection{Analogy: Automatic Differentiation}

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
& \textbf{Differentiation} & \textbf{Incremental Fixpoint} \\
\hline
Low-level & User provides $f(x)$ and $\frac{df}{dx}$ & User provides $F$, $\mathsf{stepFromDelta}$, proofs \\
\hline
High-level & User writes expression; & User writes $F$ in DSL; \\
(DSL) & system derives gradient & system derives incremental ops \\
\hline
Requirement & $f$ given as expression tree & $F$ given as composition of primitives \\
\hline
Black-box & Finite differences (slow) & Full recomputation (slow) \\
\hline
\end{tabular}
\end{center}

Just as automatic differentiation requires $f$ to be expressed as a composition of differentiable primitives, automatic incrementalization requires $F$ to be expressed as a composition of ``incrementalizable'' primitives.

\subsection{Potential DSL Primitives}

A DSL for fixpoint operators might include:
\begin{itemize}
  \item $\mathsf{const}(B)$: constant base set
  \item $\mathsf{union}(F_1, F_2)$: union of two operators
  \item $\mathsf{join}(R, S, \pi)$: join $S$ with relation $R$, project via $\pi$
  \item $\mathsf{filter}(P, S)$: filter $S$ by predicate $P$
  \item $\mathsf{lfp}(\lambda S. F(S))$: least fixpoint
\end{itemize}

Each primitive would come with:
\begin{itemize}
  \item Its incremental step function (for semi-naive)
  \item Its derivation counting semantics (for deletion)
\end{itemize}

\begin{example}[DCE in DSL]
\begin{verbatim}
live = lfp(S => 
  union(
    const(roots),
    join(edges, S, (u, v) => v)
  )
)
\end{verbatim}
The system derives:
\begin{itemize}
  \item $\mathsf{stepFromDelta}(\Delta) = \mathsf{join}(\mathsf{edges}, \Delta, (u,v) \mapsto v)$
  \item Proof that step is element-wise (each edge provides a single derivation)
  \item Proof that step is additive (union distributes over step)
\end{itemize}
\end{example}

\subsection{Connection to Datalog}

Datalog engines already perform similar derivations:
\begin{itemize}
  \item Rules are the structured representation of $F$
  \item Semi-naive evaluation is derived from rule structure
  \item Well-founded cascade generalizes deletion handling
\end{itemize}

A general incremental fixpoint DSL would extend this beyond Horn clauses to richer operators (aggregation, negation, etc.).

\section{Examples Beyond DCE}

The incremental fixpoint pattern applies to many problems:

\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Problem} & \textbf{Base} & \textbf{Step} & \textbf{Derivation Count} \\
\hline
DCE/Reachability & roots & successors & in-degree from live \\
\hline
Type Inference & base types & constraint propagation & \# constraints implying type \\
\hline
Points-to Analysis & direct assignments & transitive flow & \# flow paths \\
\hline
Call Graph & entry points & callees of reachable & \# callers \\
\hline
Datalog & base facts & rule application & \# rule firings \\
\hline
\end{tabular}
\end{center}

\section{Relationship to Reactive Systems}

In a reactive system like Skip:
\begin{itemize}
  \item \textbf{Layer 1} (reactive aggregation) handles changes to the \emph{parameters} of $F$ (e.g., the graph structure).
  \item \textbf{Layer 2} (incremental fixpoint) maintains the fixpoint as those parameters change.
\end{itemize}

The two layers compose: reactive propagation delivers deltas to the fixpoint maintainer, which incrementally updates its state and emits its own deltas (added/removed elements) for downstream consumers.

\section{Future Work}

\begin{enumerate}
  \item \textbf{Design Level 2 DSL}: Define a language of composable fixpoint operators with automatic incrementalization.
  
  \item \textbf{Integrate with Skip}: Implement the incremental fixpoint abstraction as a reusable component in the Skip reactive framework.
  
  \item \textbf{Explore stratification}: Extend to stratified fixpoints (with negation) where layers must be processed in order.
  
  \item \textbf{Benchmark}: Compare incremental vs.\ recompute performance on realistic workloads.
\end{enumerate}

\section{Conclusion}

The incremental DCE algorithm is an instance of a general pattern: maintaining least fixpoints incrementally under changes to the underlying operator.
We propose a two-level architecture:
\begin{enumerate}
  \item A \textbf{low-level API} where users provide \textsf{stepFromDelta} and prove step is element-wise and additive.
  \item A \textbf{high-level DSL} (future work) where these proofs are derived automatically from a structured definition of $F$, analogous to how automatic differentiation derives gradients from expression structure.
\end{enumerate}

The key contribution is \emph{well-founded cascade}: using the iterative construction rank to handle cycles correctly. Elements not in the new fixpoint have no finite rank, so they have no well-founded derivers and are removed.

This abstraction unifies incremental algorithms across domains (program analysis, databases, reactive systems) and provides a foundation for building efficient, correct incremental computations.

\end{document}

