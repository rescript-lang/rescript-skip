# Towards a Reactive Calculus

This note sketches a possible ‚Äúreactive calculus‚Äù that could sit underneath Skip‚Äôs combinators for building reactive views.
Reducers are the most algebraically subtle part of this story, so they get most of the attention here, but the intent is not to express everything as a reducer‚Äîonly to make the complex pieces *good by construction* rather than something users or authors must prove case‚Äëby‚Äëcase.

It is intentionally informal and future‚Äëlooking; the goal is to capture design directions, not to fix a concrete formal system yet.

## 1. Core vision

- A small, typed calculus of *reactive combinators* for building views:
  - collections as first‚Äëclass values, and
  - reducers as structured, reusable update operators on those collections.
- Well‚Äëformedness of reducers is enforced by typing rules and algebraic closure properties.
  - Every reducer term that type‚Äëchecks in the calculus either:
    - is guaranteed to satisfy the Skip well‚Äëformedness law, or
    - is explicitly classified as partial / ‚Äúfallback to recompute‚Äù.
- The calculus plays the same role for reactive views that:
  - relational algebra plays for SQL, and
  - change structures / incremental Œª‚Äëcalculus play for derivative‚Äëbased incrementalization.

## 2. Basic semantic types

At the semantic level, the calculus works with the same objects as the paper:

- `Multiset V` (`ùìú(V)`): finite multisets over values `V`, with union `‚äé` and multiset difference.
- `Collection K V`: functions `K ‚Üí ùìú(V)`; this is the semantic type for Skip collections.
- `Reducer V A`: triples `R = (Œπ, ‚äï, ‚äñ)` with:
  - `Œπ : A` ‚Äì initial accumulator,
  - `‚äï : A √ó V ‚Üí A` ‚Äì add,
  - `‚äñ : A √ó V ‚Üí A` or partial `A √ó V ‚Üí A + {‚ä•}` ‚Äì remove.

A reducer is *well‚Äëformed* when its operations satisfy the Skip laws:

- **pairwise commutativity** of add/remove steps:
  `(a ‚äï v‚ÇÅ) ‚äï v‚ÇÇ = (a ‚äï v‚ÇÇ) ‚äï v‚ÇÅ`,
  `(a ‚äñ v‚ÇÅ) ‚äñ v‚ÇÇ = (a ‚äñ v‚ÇÇ) ‚äñ v‚ÇÅ`,
  `(a ‚äï v‚ÇÅ) ‚äñ v‚ÇÇ = (a ‚äñ v‚ÇÇ) ‚äï v‚ÇÅ`
  (order‚Äëindependence of folding adds/removes);
- **invertibility law**:
  `(a ‚äï v) ‚äñ v = a`
  (removing a just‚Äëadded value restores the previous state).

Section 4 turns these semantic properties into explicit typing judgements (`WFReducer` vs `PartialReducer`).

Additional standard type constructors:

- Products `A‚ÇÅ √ó A‚ÇÇ`, sums, and perhaps function spaces as needed.
- Simple collection‚Äëlevel operators: `map`, `slice`, `merge`, etc., which are algebraically straightforward.

## 3. Core reactive building blocks

Before focusing on reducers, we surface the building blocks exposed in the Skip bindings (`EagerCollection`, `LazyCollection`, `Mapper`, `Reducer`, `LazyCompute`, external resources).
The calculus should make these first‚Äëclass and encourage a simple rule: use the simplest tool that works; reach for reducers only when necessary.

### 3.1 Structural collection operators

At the collection level, many common view patterns need no per‚Äëkey state at all; they are purely structural.
In the Skip bindings, keys `K` are JSON values (`Json` in the TypeScript API):

- booleans, numbers, strings,
- arrays of JSON or `null`,
- objects mapping string keys to JSON or `null` values.

For the calculus and examples, we fix some lightweight notation:

- finite JSON arrays are written `[v‚ÇÅ, ‚Ä¶, v‚Çô]`, where each `v·µ¢` is a JSON value or `null`;
- JSON objects are finite maps from strings to JSON, written either
  `{k‚ÇÅ ‚Ü¶ v‚ÇÅ, ‚Ä¶, k‚Çô ‚Ü¶ v‚Çô}` or `{"k‚ÇÅ": v‚ÇÅ, ‚Ä¶, "k‚Çô": v‚Çô}`,
  with the understanding that object keys are always strings.

For the calculus we assume a fixed total order `‚â§‚Ççjson‚Çé` on JSON values in order to talk about ranges and prefixes.

The order `‚â§‚Ççjson‚Çé` is defined as follows:
- Values are partitioned by JSON type (shape): `null <‚Ççjson‚Çé booleans <‚Ççjson‚Çé numbers <‚Ççjson‚Çé strings <‚Ççjson‚Çé arrays <‚Ççjson‚Çé objects`.
- Within each type:
  - `null`: there is a single value `null`.
  - Booleans: `false <‚Ççjson‚Çé true`.
  - Numbers: ordered by numeric value (standard `<` on ‚Ñù).
  - Strings: ordered lexicographically.
  - Arrays: ordered lexicographically by comparing elements from left to right; shorter arrays precede longer arrays when one is a prefix of the other.
  - Objects: ordered lexicographically by comparing key‚Äëvalue pairs `(k, v)` where keys are compared first (as strings), then values; objects with fewer keys precede objects with more keys when one's keys are a subset of the other's.

**Comparison with JavaScript sorting.** Operations like `getAll`, `slice`, and `take` return entries ordered by `‚â§‚Ççjson‚Çé`. JavaScript has no built‚Äëin total order on JSON values:
- `Array.sort()` with no comparator coerces elements to strings, so `[1, 10, 2]` sorts as `[1, 10, 2]` (string order), not `[1, 2, 10]`.
- Mixed types have inconsistent behaviour: `null < 0` is `false`, `true < 2` is `true` (coerces to `1 < 2`).
- Arrays and objects cannot be compared with `<`; they coerce to strings.

In practice, JS developers work around this by sorting homogeneous data (all numbers, all strings) or writing custom comparators for specific object shapes. Libraries like Lodash provide `_.sortBy(collection, iteratee)` to sort by a derived key, but not a general‚Äëpurpose total order on arbitrary JSON.

The one exception in the web platform is **IndexedDB**, which defines a key ordering: `number < Date < string < binary < array` (with arrays compared lexicographically). This is similar in spirit to `‚â§‚Ççjson‚Çé`, though the type ordering and supported types differ.

> **Known issue (to be fixed):** The current WASM binding serializes booleans as numbers (0/1) when exporting to JavaScript. This does not affect the runtime's internal ordering or key identity‚Äîonly the JavaScript representation.

- `map : Collection K V ‚Üí Collection K' V'` (entry‚Äëwise transformation): apply a mapping function to each `(key, values)` group, possibly changing keys and values.
- `slice : Collection K V √ó K √ó K ‚Üí Collection K V` (key range): given `start, end : K`, keep only entries whose keys lie between `start` and `end` in the runtime's key order.
- `slices : Collection K V √ó (K √ó K) list ‚Üí Collection K V` (multi‚Äërange): keep entries whose keys lie in at least one of a finite set of such ranges.
- `take : Collection K V √ó int ‚Üí Collection K V` (prefix): keep the first `n` entries in the runtime's key order.
- `merge : (Collection K V) list ‚Üí Collection K V` (union): combine a finite family of collections so that at each key the values are the multiset union of values from all inputs.

These operators:

- are total and order‚Äëinsensitive by construction,
- do not maintain additional state beyond their inputs, and
- introduce no new well‚Äëformedness obligations beyond typing.

In the calculus, they form the ‚Äúalways safe‚Äù fragment: compositional operators on `Collection K V` that can be freely combined without thinking about reducer laws.

### 3.2 Per‚Äëkey aggregation views

Per‚Äëkey aggregation is where `Reducer V A` enters the picture.
Given a collection `Collection K V`, a reducer accumulates all values at a given key into an accumulator of type `A`.
Skip's API exposes this via `EagerCollection.reduce` and `EagerCollection.mapReduce`.

Typical examples include:

- counts, sums, min/max, and other numeric aggregates,
- enriched accumulators like `(sum, count)` for averages, or `(min, secondMin, count)` for robust minima,
- small per‚Äëkey summaries (e.g. flags, bounded histograms) that can be updated incrementally.

At this level, a reducer is the triple `(Œπ, ‚äï, ‚äñ)` used to fold per‚Äëkey multisets.
The key pragmatic principle:

- Express a view as a structural operator (`map`, `slice`, `merge`, ‚Ä¶) plus a simple, standard reducer on a small accumulator.
- Use more exotic reducers only when simple ones are not expressive or efficient enough.

The more delicate algebraic laws (well‚Äëformedness, complexity) are introduced in later sections.

### 3.3 Lazy and external compute nodes

Some views are not naturally expressed as a single per‚Äëkey reducer, even with enriched state:

- they may depend on global structure (graphs, fixpoints, cross‚Äëkey relationships), or
- they may be sourced from or delegated to external systems.

The bindings reflect this via:

- `LazyCollection` / `LazyCompute`: on‚Äëdemand views computed by a function `compute : (LazyCollection K V, key, context, params) ‚Üí array V`, and
- `Context.useExternalResource`: eager collections backed by external services or APIs.

In the reactive calculus, these are best modelled as *compute nodes* in the graph rather than as reducers:

- they consume one or more collections and produce a new collection,
- they are specified by a semantic contract (‚Äúthis node computes X from its inputs‚Äù) rather than reducer laws,
- they may internally run iterative or graph algorithms (as in the DCE case study).

The calculus distinguishes:

- the **reducer fragment**, where well‚Äëformedness and incremental complexity are controlled algebraically, from
- the **compute fragment** for nodes specified relationally or operationally but not necessarily as invertible reducers.

### 3.4 ‚ÄúSimplest tool that works‚Äù hierarchy

Putting these pieces together suggests a pragmatic hierarchy for building reactive views:

1. **Structural operators on collections** (`map`, `slice`, `slices`, `take`, `merge`, key/value remapping).
2. **Standard per‚Äëkey reducers** (sum, count, min/max, simple enriched accumulators).
3. **Custom/enriched reducers** when the accumulator needs more structure for incremental performance or invertibility.
4. **Compute nodes and external resources** (lazy computes, graph algorithms, remote services) when the logic is global or not reducer‚Äëlike.

The rest of the note focuses on (2) and (3), developing an algebra and type system for reducers, but should be read in the context of this wider toolkit.
In practice, most Skip views are built from (1) and (2), reserving (3) and (4) for more complex cases.

## 4. Well‚Äëformedness as a typing judgement

In the paper, well‚Äëformedness is a semantic property (the laws from Section 2).
In the calculus, this becomes an explicit typing judgement:

- `Œì ‚ä¢ R : Reducer V A` ‚Äì `R` is syntactically a reducer.
- `Œì ‚ä¢ R : WFReducer V A` ‚Äì `R` is well‚Äëformed; it satisfies the semantic correctness law.
- Optionally, `Œì ‚ä¢ R : PartialReducer V A` ‚Äì `R` may fall back to recomputation.

The goal is to arrange the rules so that:

- Base primitives are declared well‚Äëformed by assumption.
- Combinators on reducers *preserve* well‚Äëformedness, so complex reducers built from well‚Äëformed pieces remain well‚Äëformed automatically.

These judgements are specific to the reducer fragment.
Structural collection operators (Section 3.1) and compute nodes (Section 3.3) are constrained by their own semantic contracts and do not need to satisfy the Skip reducer laws.

## 5. Algebra of reducers

Within the broader reactive calculus, we can turn common constructions on reducers into typed combinators, along lines such as:

- **Product of reducers**
  - Given `Œì ‚ä¢ R‚ÇÅ : WFReducer V A‚ÇÅ` and `Œì ‚ä¢ R‚ÇÇ : WFReducer V A‚ÇÇ`,
  - define `R‚ÇÅ ‚äó R‚ÇÇ : WFReducer V (A‚ÇÅ √ó A‚ÇÇ)` with
    - `(Œπ‚ÇÅ, ‚äï‚ÇÅ, ‚äñ‚ÇÅ)` and `(Œπ‚ÇÇ, ‚äï‚ÇÇ, ‚äñ‚ÇÇ)` combined componentwise.
  - The calculus includes a rule stating that `‚äó` preserves well‚Äëformedness.

- **Mapping value types**
  - Given a function `f : V' ‚Üí V` and `Œì ‚ä¢ R : WFReducer V A`,
  - define `mapValue f R : WFReducer V' A`, which simply pre‚Äëcomposes inputs with `f`.

- **State enrichment / refinement**
  - E.g., going from `min` over `‚Ñù` to a reducer over richer state `(min, secondMin, count)` that makes the remove operation invertible.
  - Generic combinators could pair a reducer with auxiliary state, with closure rules tracking whether invertibility is preserved.

Each such operation comes with a small metatheorem: if the premises are well‚Äëformed, the result is well‚Äëformed. Together, they give a ‚Äúgood by construction‚Äù algebra of reducers.

## 6. Complexity annotations

In the current paper, well‚Äëformedness implies a complexity contract: under the Skip semantics, well‚Äëformed reducers admit `O(1)` per‚Äëkey updates.

The calculus could refine the typing judgement to track complexity:

- `Œì ‚ä¢ R : WFReducer[V, A, O(1)]`
- `Œì ‚ä¢ R : PartialReducer[V, A, fallback]`

and give rules such as:

- Product of two `O(1)` reducers is `O(1)`.
- Product of an `O(1)` reducer with a partial reducer is partial.

This turns the calculus into a discipline not just for correctness but also for incremental performance guarantees.

## 7. Expressivity and examples

A key research question is: how expressive can such a calculus be while keeping the rules simple and checkable?

Potential sources of ‚Äúreal‚Äù reducers to test expressivity:

- Existing Skip service graphs: per‚Äëkey metrics, dashboards, alerts.
- Streaming/windowed analytics: counts, sums, averages, histograms, per‚Äësession stats.
- Domain‚Äëspecific examples: incremental graph metrics, per‚Äëuser quotas, shopping carts, etc.

The file `examples_all.tex` collects a concrete catalogue of such examples, organized into:

- **Simple per‚Äëkey aggregates** (counts, sums, min/max), which map directly to per‚Äëkey well‚Äëformed reducers (`Reducer V A` plus grouping).
- **Enriched‚Äëstate views** (averages, min/max with witnesses, multi‚Äëfield KPIs) corresponding to the "state enrichment / refinement" patterns in Section 5.
- **Set/index views** (distinct counts, membership sets, secondary indexes) that highlight when reducers should be classified as partial (e.g. recomputing a set on delete) versus fully invertible.
- **Windowed/session views** that are algebraically simple once a window identifier is part of the key, but which rely on external ‚Äúwindow management‚Äù logic to decide when keys appear or expire.
- **History/ordered‚Äëstate patterns** where accumulators store ordered structures (logs, top‚Äëk, last‚ÄëN), often trading invertibility for expressive power and landing in the `PartialReducer` fragment.
- **Graph and relational incremental views** (joins, reachability, fixpoint‚Äëstyle algorithms) that typically decompose into:
  - one or more invertible reducers over base collections (e.g. maintaining edge sets or adjacency maps), and
  - a higher‚Äëlevel incremental algorithm or fixpoint scheduler.
- **Business/UI‚Äëcomposed summaries** that combine multiple reducer‚Äëbacked resources with simple pointwise arithmetic or logical combinations.

The catalogue serves as a stress‚Äëtest for the calculus design:

- Most "everyday analytics" examples fall cleanly into the `WFReducer` fragment, possibly with enriched state.
- Windowing and history views suggest lightweight primitives at the key/type level (time buckets, sequence numbers) rather than fundamentally new reducer laws.
- Graph/relational and iterative examples (including reactive DCE, see Section 9) motivate a *layered* approach:
  - base collections and indices are maintained by well‚Äëformed reducers, and
  - global algorithms are expressed as separate reactive nodes that consume these collections rather than as single monolithic reducers.

Most examples stay in the structural + standard‚Äëreducer fragment (hierarchy from Section 3.4), with only a minority needing custom reducers or general compute nodes.

The hypothesis is that:

- A small set of primitive well‚Äëformed reducers (sum, count, min/max with enriched state, average with (sum,count) state, etc.), plus algebraic combinators (product, mapping, grouping), may cover a large fraction of real‚Äëworld reducers used in reactive back‚Äëends.
- Systematically validating this hypothesis is future work.

## 8. User‚Äëfacing layer

The calculus is intended as a foundation, not necessarily the surface language.

Two possible user‚Äëfacing stories:

- **Embedded combinator library**
  - Export the calculus directly as a small set of combinators in ReScript/TypeScript (e.g., `Reducer.product`, `Reducer.mapValue`, etc.).
  - Developers build reducers using these combinators; the type system and library design ensure well‚Äëformedness and known complexity where advertised.

- **Higher‚Äëlevel ‚Äúview query‚Äù DSL**
  - Define a more intuitive DSL for derived views, analogous to SQL over collections.
  - The compiler lowers this DSL into terms of the reactive calculus, choosing specific reducer constructions.
  - Correctness and complexity guarantees are inherited from the calculus, just as SQL inherits guarantees from relational algebra.

In both cases, the long‚Äëterm goal is that:

- Developers mostly compose *well‚Äëformed* reducers using high‚Äëlevel constructs.
- The runtime‚Äôs correctness theorem applies automatically to anything expressible in the calculus (or in the DSL compiled to it).
- Only a small, clearly marked ‚Äúescape hatch‚Äù is needed for ad‚Äëhoc reducers that fall outside the calculus, and those carry explicit ‚Äúpartial / may recompute‚Äù semantics.

## 9. Case study: reactive DCE and graph views

The LaTeX note `dce_reactive_view.tex` and Lean artefacts (`lean-formalisation/Reduce.lean`, `lean-formalisation/DCE.lean`) provide a worked example: online dead‚Äëcode elimination over a distributed program graph.

The design there is intentionally two‚Äëlayered:

- **Layer 1: graph aggregation as an invertible reducer.**
  - Each file contributes a fragment `(nodes, roots, edges)`; fragments live in a multiset.
  - A reducer over fragments maintains global multisets of nodes, roots, and edges:
    `G ‚äï f` adds the fragment componentwise; `G ‚äñ f` subtracts it.
  - Using multisets makes `‚äï`/`‚äñ` pairwise‚Äëcommutative and ensures `(G ‚äï f) ‚äñ f = G`.
    This instantiates a `WFReducer` (Section 4) whose well‚Äëformedness is proved in `reduce.tex` and the Lean files.

- **Layer 2: incremental liveness as a graph algorithm.**
  - Given the aggregated graph `G`, the view partitions nodes into live vs. dead.
  - An incremental algorithm maintains:
    - a live set, and
    - per‚Äënode refcounts for incoming edges from live predecessors.
  - It updates on each graph delta by BFS‚Äëstyle propagation and "cascade‚Äëdeath" when refcounts hit zero.
  - This logic is *not* an invertible reducer: it relies on full graph state and involves fixpoint‚Äëlike propagation.
    Its state is specified relationally (reachability from roots) and proved delta‚Äëbounded in Lean.
